# Server Configuration
SERVER_PORT=8080
GIN_MODE=release

# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_USER=postgres
DB_PASSWORD=your_password
DB_NAME=llm_router
DB_SSL_MODE=disable

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# LLM Provider API Keys
OPENAI_API_KEY=sk-xxx
OPENAI_BASE_URL=https://api.openai.com/v1
ANTHROPIC_API_KEY=sk-ant-xxx
ANTHROPIC_BASE_URL=https://api.anthropic.com
GOOGLE_API_KEY=xxx
GOOGLE_BASE_URL=https://generativelanguage.googleapis.com

# Local LLM Providers (for development/testing)
# Ollama - runs locally on port 11434
OLLAMA_API_KEY=
OLLAMA_BASE_URL=http://host.docker.internal:11434
# LM Studio - runs locally on port 1234
LMSTUDIO_API_KEY=lm-studio
LMSTUDIO_BASE_URL=http://host.docker.internal:1234/v1

# Proxy Pool Configuration
PROXY_POOL_ENABLED=true
PROXY_POOL_URL=http://proxy-pool:8080

# Health Check Configuration
HEALTH_CHECK_ENABLED=true
HEALTH_CHECK_INTERVAL=60
HEALTH_CHECK_TIMEOUT=10
HEALTH_CHECK_RETRY_COUNT=3
HEALTH_CHECK_FAILURE_THRESHOLD=3

# Alert Configuration
ALERT_ENABLED=true
ALERT_WEBHOOK_URL=https://your-webhook-url
ALERT_EMAIL_ENABLED=false
ALERT_EMAIL_SMTP_HOST=smtp.example.com
ALERT_EMAIL_SMTP_PORT=587
ALERT_EMAIL_FROM=alert@example.com
ALERT_EMAIL_TO=admin@example.com

# JWT Configuration
JWT_SECRET=your-jwt-secret-key-at-least-32-characters
JWT_EXPIRES_IN=24h

# Rate Limiting
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS_PER_MINUTE=60

# Logging
LOG_LEVEL=info
LOG_FORMAT=json

# Default Admin User (created on first startup if not exists)
ADMIN_EMAIL=admin@example.com
ADMIN_PASSWORD=changeme
ADMIN_NAME=Administrator
